{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load modules\n",
    "\n",
    "Remember to set model name. OpenAI updates model name and the old ones may become invalid\n",
    "\n",
    "e.g. gpt-4o-mini-2024-07-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/site-packages (1.68.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/xiyuancao/Library/Python/3.11/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment variables\n",
    "\n",
    "model_name = \"gpt-4o-mini-2024-07-18\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "#testing if the key works\n",
    "response = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.topics = {}\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI API key\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Candidate topics list\n",
    "candidate_topics = [\n",
    "    \"Gender roles\", \"Family structure\", \"Parenting\", \"Marriage\", \n",
    "    \"Childhood\", \"Work-life balance\", \"Caregiving\", \"Inheritance\", \n",
    "    \"Education\", \"Divorce\", \"Religion and family\", \"Adoption\", \n",
    "    \"Domestic labor\", \"Migration\", \"Generational conflict\"\n",
    "]\n",
    "\n",
    "def build_structured_response(question, answer):\n",
    "    system_message = \"You are a helpful assistant tasked with tagging conversations based on their content using a structured JSON schema.\"\n",
    "    user_message = f\"\"\"\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "From this list of candidate topics:\n",
    "{', '.join(candidate_topics)}\n",
    "\n",
    "Return a JSON object with a field 'relevant_topics' containing 1â€“3 matching topic strings.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.responses.create(\n",
    "        model=model_name,\n",
    "        input=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        text={\n",
    "            \"format\": {\n",
    "                \"type\": \"json_schema\",\n",
    "                \"name\": \"row_topic_extraction\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"relevant_topics\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"type\": \"string\"}\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"relevant_topics\"],\n",
    "                    \"additionalProperties\": False\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return json.loads(response.output_text)[\"relevant_topics\"]\n",
    "\n",
    "\n",
    "def single_csv_classification(file_obj, output_folder):\n",
    "    df = pd.read_csv(file_obj.file_path)\n",
    "    df[\"topics\"] = \"\"\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            question = row[\"question\"]\n",
    "            answer = row[\"answer\"]\n",
    "            topics = build_structured_response(question, answer)\n",
    "\n",
    "            df.at[i, \"topics\"] = topics\n",
    "\n",
    "            # Count topic frequencies\n",
    "            for topic in topics:\n",
    "                file_obj.topics[topic] = file_obj.topics.get(topic, 0) + 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error at row {i}: {e}\")\n",
    "            df.at[i, \"topics\"] = []\n",
    "\n",
    "    # Save to file\n",
    "    filename = Path(file_obj.file_path).stem\n",
    "    df.to_csv(f\"{output_folder}/{filename}_labeled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the folder path\n",
    "folder_path = Path(\"Phase2_Folders/030_processed_html\")\n",
    "\n",
    "output_folder= \"topic_labeling\"\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Dictionary to store results\n",
    "files = {}\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for file_path in folder_path.glob(\"*.csv\"):\n",
    "    file_obj = File(file_path)\n",
    "    single_csv_classification(file_obj)\n",
    "    files[file_path.name] = file_obj  # Save the object if you want to access topic counts later\n",
    "\n",
    "# Example: Print topic counts from all files\n",
    "for fname, file_obj in files.items():\n",
    "    print(f\"\\nðŸ“„ {fname}\")\n",
    "    for topic, count in file_obj.topics.items():\n",
    "        print(f\"  {topic}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
